##Method Search & Software:

###Links:

[DeepLabCut Official](http://www.mackenziemathislab.org/deeplabcut-home)  
[DeepLabCut GitHub](https://github.com/DeepLabCut)

###DeepLabCut:
1. DeepLabCut is a software package designed for 2D and 3D markerless pose estimation based on transfer learning with deep neural networks. DeepLabCut is very accurate and efficient and requires minimal training data as well. The versatility of this framework is demonstrated by tracking various body parts in multiple species across a broad collection of behaviors. The package is open source, fast, robust, and can be used to compute 3D pose estimates or for multi-animals. This package is collaboratively developed by the Mathis Group & Mathis Lab at EPFL (releases prior to 2.1.9 were developed at Harvard University).
2. To use DeepLabCut you can use their own GUI, their Jupyter Notebook, their Google Colab, or your own terminal. They also provide lots of data that helps you demo the package and test installation.![image](https://github.com/agoel11/KEYS2023/assets/81878922/e87628ff-14ee-47bd-8a0d-3c8b2295feef)
3. DeepLabCut has been used for trail tracking, reaching in mice, and various Drosophila behaviours during egg-laying. But this toolbox has a variety of applications and it has already been applied to rats, humans, various fish species, bacteria, leeches, various robots, cheetahs, mouse whiskers and race horses. DeepLabCut utilizes the feature detectors (ResNets + readout layers) of one of the state-of-the-art algorithms for human pose estimation by Insafutdinov et al., called DeeperCut. They have improved the inference speed and provided both additional and novel augmentation methods, added real-time, and multi-animal support and currently provide state-of-the-art performance for animal pose estimation.
4. Because of transfer learning, the package requires little training data for multiple challenging behaviors. The feature detectors are robust to video compression. It allows 3D pose estimation with a single network and camera. It allows 3D pose estimation with a single network trained on data from multiple cameras together with standard triangulation methods. DeepLabCut is embedding in a larger open-source eco-system, providing behavioral tracking for neuroscience, ecology, medical, and technical applications. ![image](https://github.com/agoel11/KEYS2023/assets/81878922/cd61a3ad-5a8f-415c-ab18-ec0fe46b77af)
5. ####[DeepLabCut: Markerless Pose Estimation of User-Defined Body Parts With Deep Learning](https://doi.org/10.1038/s41593-018-0209-y)
    1. New methods for markerless tracking using deep learning and neural networks. Excellent performance, comparable to human accuracy. Minimal training data also yields excellent results across various species and behaviors.
    2. Quantification of behavior essential for understanding brain. Computer vision much easier and more efficient than manual analysis. Markers, used traditionally, invade space and aren't cost effective and are distracting to subjects. Deep learning architecture greatly improve accuracy of pose estimation. Large datasets can be tackled by using transfer learning.
    3. Used feature detection architecture from DeeperCut (best pose estimation algorithms, can acheieve human-level labeling accuracy with minimal data). Result of transfer learning, feature detectors are based on extremely deep neural networks, which were pretrained on ImageNet, a massive dataset for object recognition.
    4. DeeperCut achieves outstanding performance on multi-human pose detection benchmarks, trained on thousands of labeled images. DeepLabCut is DeeperCut but focuses on feature detectors, which are variations of deep residual neural networks (ResNet) with readout layers that predict the location of a body part.
    5. DeepLabCut is a deep convolutional network combining two key ingredients from object recognition and semantic segmentation: pretrained ResNets and deconvolutional layers. The network consists of a variant of ResNets, whose weights were trained on a popular, large-scale object recognition benchmark called ImageNet. Deconvolutional layers are used to up-sample the visual information and produce spatial probability densities. For each body part, its probability density represents the ‘evidence’ that a body part is in a particular location. To fine-tune the network for a particular task, its weights are trained on labeled data, which consist of frames and the accompanying annotated body part locations. The weights are adjusted in an iterative fashion such that for a given frame the network assigns high probabilities to labeled body part locations and low probabilities elsewhere. The network is rewired and ‘learns’ feature detectors for the labeled body parts. ![image](https://github.com/agoel11/KEYS2023/assets/81878922/028d8ebb-13f3-4bd4-8882-37e622e7711c)
    6. 
