##Method Search & Software:

###Links:

[DeepLabCut Official](http://www.mackenziemathislab.org/deeplabcut-home)  
[DeepLabCut GitHub](https://github.com/DeepLabCut)

###DeepLabCut:
1. DeepLabCut is a software package designed for 2D and 3D markerless pose estimation based on transfer learning with deep neural networks. DeepLabCut is very accurate and efficient and requires minimal training data as well. The versatility of this framework is demonstrated by tracking various body parts in multiple species across a broad collection of behaviors. The package is open source, fast, robust, and can be used to compute 3D pose estimates or for multi-animals. This package is collaboratively developed by the Mathis Group & Mathis Lab at EPFL (releases prior to 2.1.9 were developed at Harvard University).
2. To use DeepLabCut you can use their own GUI, their Jupyter Notebook, their Google Colab, or your own terminal. They also provide lots of data that helps you demo the package and test installation.![image](https://github.com/agoel11/KEYS2023/assets/81878922/e87628ff-14ee-47bd-8a0d-3c8b2295feef)
3. DeepLabCut has been used for trail tracking, reaching in mice, and various Drosophila behaviours during egg-laying. But this toolbox has a variety of applications and it has already been applied to rats, humans, various fish species, bacteria, leeches, various robots, cheetahs, mouse whiskers and race horses. DeepLabCut utilizes the feature detectors (ResNets + readout layers) of one of the state-of-the-art algorithms for human pose estimation by Insafutdinov et al., called DeeperCut. They have improved the inference speed and provided both additional and novel augmentation methods, added real-time, and multi-animal support and currently provide state-of-the-art performance for animal pose estimation.
4. Because of transfer learning, the package requires little training data for multiple challenging behaviors. The feature detectors are robust to video compression. It allows 3D pose estimation with a single network and camera. It allows 3D pose estimation with a single network trained on data from multiple cameras together with standard triangulation methods. DeepLabCut is embedding in a larger open-source eco-system, providing behavioral tracking for neuroscience, ecology, medical, and technical applications. ![image](https://github.com/agoel11/KEYS2023/assets/81878922/cd61a3ad-5a8f-415c-ab18-ec0fe46b77af)
5. ####[DeepLabCut: Markerless Pose Estimation of User-Defined Body Parts With Deep Learning](https://doi.org/10.1038/s41593-018-0209-y)
    1. New methods for markerless tracking using deep learning and neural networks. Excellent performance, comparable to human accuracy. Minimal training data also yields excellent results across various species and behaviors.
    2. Quantification of behavior essential for understanding brain. Computer vision much easier and more efficient than manual analysis. Markers, used traditionally, invade space and aren't cost effective and are distracting to subjects. Deep learning architecture greatly improve accuracy of pose estimation. Large datasets can be tackled by using transfer learning.
    3. Used feature detection architecture from DeeperCut (best pose estimation algorithms, can acheieve human-level labeling accuracy with minimal data). Result of transfer learning, feature detectors are based on extremely deep neural networks, which were pretrained on ImageNet, a massive dataset for object recognition.
    4. DeeperCut achieves outstanding performance on multi-human pose detection benchmarks, trained on thousands of labeled images. DeepLabCut is DeeperCut but focuses on feature detectors, which are variations of deep residual neural networks (ResNet) with readout layers that predict the location of a body part.
    5. DeepLabCut is a deep convolutional network combining two key ingredients from object recognition and semantic segmentation: pretrained ResNets and deconvolutional layers. The network consists of a variant of ResNets, whose weights were trained on a popular, large-scale object recognition benchmark called ImageNet. Deconvolutional layers are used to up-sample the visual information and produce spatial probability densities. For each body part, its probability density represents the ‘evidence’ that a body part is in a particular location. To fine-tune the network for a particular task, its weights are trained on labeled data, which consist of frames and the accompanying annotated body part locations. The weights are adjusted in an iterative fashion such that for a given frame the network assigns high probabilities to labeled body part locations and low probabilities elsewhere. The network is rewired and ‘learns’ feature detectors for the labeled body parts. ![image](https://github.com/agoel11/KEYS2023/assets/81878922/028d8ebb-13f3-4bd4-8882-37e622e7711c)
    6. Average variability to ground truth was found to be very low and small. To quantidy accuracy, datasets were split and a certain percentage was used to train while the rest was used to test. When trained with 80% of
the data the algorithm achieved human-level accuracy. After varying training and testing percentages, it was found that even 100 frames were enough to achieve excellent generalization. Data augmentation (such as rotations or translations) also resulted in minimal differences, demonstrating the data-efficiency of DeepLabCut. ![image](https://github.com/agoel11/KEYS2023/assets/81878922/6bf3d011-6145-458d-9e50-d91172aac2c4)
    7. The feature detectors were able to translate pretty well to novel mouse behaviors as well as videos with multiple mice. Although it wasn't error free, this can be improved by simply training on that data or on data for multiple mice. ![image](https://github.com/agoel11/KEYS2023/assets/81878922/b9e8c1d2-aebe-410d-be88-d239c2f84903)
    8. End-to-end training allows the model to facilitate the localization of one body part based on other labeled body parts. The network that was trained with all body part labels simultaneously outperforms the specialized networks nearly twofold. ![image](https://github.com/agoel11/KEYS2023/assets/81878922/88060d7d-89ba-44d2-8b36-90f7c40824f5)
    9. Temporal information could indeed be beneficial in certain contexts, challenges remain to using end-to-end-trained deep architectures for video data to extract postures. Because of the curse of dimensionality, deep architectures on videos must rely on input images with lower spatial resolution, and thus the best-performing action recognition algorithms still rely on frame-by-frame analysis with deep networks pretrained on ImageNet as a result of hardware limitations. Therefore currently, in situations where occlusions are very common, such as in social behaviors, pairwise interactions could also be added to improve performance
