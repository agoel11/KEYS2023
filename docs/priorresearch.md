#Prior Research/ Initial Fact-finding

Project Description:                                                                                                                                                              
![image](https://github.com/agoel11/KEYS2023/assets/81878922/77e2dfbd-7cde-4ee9-9cde-72bf51fa559a)

##Concepts Overview

###Links                                                                                                                                                                                                              
[What is Deep Learning](https://aws.amazon.com/what-is/deep-learning/#:~:text=Deep%20learning%20is%20a%20method,produce%20accurate%20insights%20and%20predictions.)

###Deep Learning
1. Deep learning is a method in artificial intelligence (AI) that teaches computers to process data in a way that is inspired by the human brain. Deep learning models can recognize complex patterns in pictures, text, sounds, and other data to produce accurate insights and predictions. Deep learning methods can also be used to automate tasks that typically require human intelligence, such as describing images or transcribing a sound file into text.
2. Deep learning is used heavily in many different machine learning use cases and concepts like computer vision, speech recognition, natural language processing, and recommendation engines. Computer vision is the computer's ability to extract information and insights from images and videos. Computers can use deep learning techniques to comprehend images in the same way that humans do. Deep learning models can analyze human speech despite varying speech patterns, pitch, tone, language, and accent. Computers use deep learning algorithms to gather insights and meaning from text data and documents. Applications can use deep learning methods to track user activity and develop personalized recommendations. They can analyze the behavior of various users and help them discover new products or services.
3. Deep learning models use neural networks which contain thousands of artificial nodes and neurons in order to process data in a way similar to humans. These networks contains many layers that process data from the input layer and release the processed data to the output layer.
4. The input layer of a artificial neural network (ANN) has several nodes that input data into the network. The data is then passed into the hidden layer which processes and passes the data to layers further in the neural network. These hidden layers process information at different levels, adapting their behavior as they receive new information. Deep learning networks have hundreds of hidden layers that they can use to analyze a problem from several different angles. The processed data is then passed into the output layer which consists of the nodes that output the data. Deep learning models that output "yes" or "no" answers have only two nodes in the output layer. On the other hand, those that output a wider range of answers have more nodes.
![image](https://github.com/agoel11/KEYS2023/assets/81878922/d0c29fc8-fb2d-4fcb-80be-4b137b7585cb)
6. Deep learning is a subset of machine learning. Deep learning algorithms emerged in an attempt to make traditional machine learning techniques more efficient. Traditional machine learning methods utilize what is known as supervised learning in which the humans have to assist in training the machine. Deep learning generally relies on unsupervised learning and finds patterns in the data on its own, therefore making it much more efficient.
7. Deep learning is better than machine learning because of a couple reasons. Deep learning models can comprehend unstructured data and make general observations without manual feature extraction. A deep learning application can analyze large amounts of data more deeply and reveal new insights for which it might not have been trained. In this way deep learning has an advantage for finding hidden relationships and discovering patterns. Deep learning models can learn and improve over time based on user behavior. They do not require large variations of labeled datasets. Once again, this is where unsupervised learning benefits deep learning models.
8. However deep learning models have some drawbacks as well. They work a lot better when they are trained on large, high-quality datasets, and outliers or mistakes in the input dataset can significantly affect the deep learning process. Because of this, deep learning requires lots of data pre-processing and data storage capacity as well. Deep learning algorithms are also compute-intensive and require infrastructure with sufficient compute capacity to properly function. Otherwise, they take a long time to process results.

###Video Segmentation

##Research Papers

###Links

###Notes

##Current Methods

###Links

###Notes
